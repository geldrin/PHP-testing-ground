user www-data;

worker_processes 4;

#error_log /var/log/nginx/error.log;
error_log /var/log/nginx/error.log notice;
#error_log /var/log/nginx/error.log info;
#error_log /var/log/nginx/error.log debug;

pid /var/run/nginx.pid;

# worker_processes * worker_connections = maxclients
events {
	worker_connections 256;
}

# set open fd limit to 30000
worker_rlimit_nofile 30000;

http {
	include       mime.types;
	default_type  application/octet-stream;

	log_format main '$remote_addr - $remote_user [$time_local] "$request" '
		'$status $body_bytes_sent "$http_referer" '
		'"$http_user_agent" "$http_x_forwarded_for"';

	access_log /var/log/nginx/access.log;

	sendfile on;
	tcp_nopush on;
	keepalive_timeout 65;

	gzip off;

	# Log: cache status
	log_format cache '$remote_addr [$time_local] | '
		'$scheme | '
		'*$upstream_cache_status* | '
		'Cache-Control: $upstream_http_cache_control | '
		'Expires: $upstream_http_expires | '
#		'upstream_server: $upstream_addr | '
#		'upstream_status: $upstream_status | '
		'"$request" ($status) | '
		'$body_bytes_sent bytes | '
		'"$http_user_agent" | '
		'key: $proxy_host$uri';

	# Access log file for cache status
	access_log  /var/log/nginx/cache.log cache;

	## Cache configuration

	# Syntax: proxy_buffering on | off;
	# Default: proxy_buffering on;
	#
	# Enables or disables buffering of responses from the proxied server. When buffering is enabled,
	# nginx receives a response from the proxied server as soon as possible, saving it into the buffers
	# set by the proxy_buffer_size and proxy_buffers directives. If the whole response does not fit into memory,
	# a part of it can be saved to a temporary file on the disk. Writing to temporary files is controlled by
	# the proxy_max_temp_file_size and proxy_temp_file_write_size directives.
	proxy_buffering on;

	# Syntax: proxy_cache_path path [levels=levels] keys_zone=name:size [inactive=time] [max_size=size] [loader_files=number] [loader_sleep=time] [loader_threshold=time];
	# Default: -
	#
	# File storage: Sets the path and other parameters of a cache. Cache data are stored in files. The file name in a cache is a
	# result of applying the MD5 function to the cache key. The levels parameter defines hierarchy levels of a cache.
	# For example, in the following configuration:
	#  proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;
	#  file names in a cache will look like this:
	#  /data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c
	#
	# Cache directories and file systems: A cached response is first written to a temporary file, and then the file is renamed.
	# Starting from version 0.8.9, temporary files and the cache can be put on different file systems. However, be aware that in
	# this case a file is copied across two file systems instead of the cheap renaming operation. Thus it is recommended that for any
	# given location both cache and a directory holding temporary files, set by the proxy_temp_path directive, are put on the same file system.
	#
	# key_zone: In addition, all active keys and information about data are stored in a shared memory zone, whose name and size are
	# configured by the keys_zone parameter. One megabyte zone can store about 8 thousand keys.
	#
	# Cached data that are not accessed during the time specified by the inactive parameter get removed from the cache
	# regardless of their freshness. By default, inactive is set to 10 minutes.
	#
	# max_size: The special “cache manager” process monitors the maximum cache size set by the max_size parameter.
	# When this size is exceeded, it removes the least recently used data.
	#
	# A minute after the start the special "cache loader" process is activated. It loads information about previously
	# cached data stored on file system into a cache zone. The loading is done in iterations. During one iteration
	# no more than loader_files items are loaded (by default, 100). Besides, the duration of one iteration is limited
	# by the loader_threshold parameter (by default, 200 milliseconds). Between iterations, a pause configured
	# by the loader_sleep parameter (by default, 50 milliseconds) is made.
	proxy_cache_path /data/nginx/cache/ levels=1:2 keys_zone=edge-cache:20m inactive=7d max_size=5g;

	# Syntax: proxy_temp_path path [level1 [level2 [level3]]];
	# Default: proxy_temp_path proxy_temp;
	# Example: proxy_temp_path /spool/nginx/proxy_temp 1 2;
	#
	# Defines a directory for storing temporary files with data received from proxied servers. Up to three-level
	# subdirectory hierarchy can be used underneath the specified directory. For example, in the above configuration
	# a temporary file might look like this: /spool/nginx/proxy_temp/7/45/00000123457
	proxy_temp_path /data/nginx/temp 1 2;

	# Syntax: proxy_cache_valid [code ...] time;
	#
	# Sets caching time for different response codes. For example, the following directives
	#  proxy_cache_valid 200 302 10m;
	#  proxy_cache_valid 404      1m;
	# set 10 minutes of caching for responses with codes 200 and 302 and 1 minute for responses with code 404.
	#
	# If only caching time is specified
	#  proxy_cache_valid 5m;
	# then only 200, 301, and 302 responses are cached.
	#
	# In addition, the any parameter can be specified to cache any responses:
	# proxy_cache_valid 200 302 10m;
	# proxy_cache_valid 301      1h;
	# proxy_cache_valid any      1m;
	proxy_cache_valid any 10m;

	# Syntax: proxy_cache_lock on | off;
	# Default: proxy_cache_lock off;
	#
	# When enabled, only one request at a time will be allowed to populate a new cache element
	# identified according to the proxy_cache_key directive by passing a request to a proxied server.
	# Other requests of the same cache element will either wait for a response to appear in the cache
	# or the cache lock for this element to be released, up to the time set by the proxy_cache_lock_timeout directive.
	proxy_cache_lock on;

	# Syntax: proxy_cache_use_stale error | timeout | invalid_header | updating | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | off ...;
	# Default: proxy_cache_use_stale off;
	#
	# Determines in which cases a stale cached response can be used when an error occurs during communication with the proxied server.
	# The directive’s parameters match the parameters of the proxy_next_upstream directive.
	#
	# Additionally, the updating parameter permits using a stale cached response if it is currently being updated.
	# This allows minimizing the number of accesses to proxied servers when updating cached data.
	#
	# To minimize the number of accesses to proxied servers when populating a new cache element, the proxy_cache_lock directive can be used.
	proxy_cache_use_stale updating;

	# Syntax: proxy_cache_key string;
	# Default: proxy_cache_key $scheme$proxy_host$request_uri;
	# Cache key: only URL (no protocol, no host, no args - provides same keys for http/https)
	proxy_cache_key $uri;

# Komplett leiras
# http://docs.unified-streaming.com/tutorials/caching/reverse-proxy.html
# Varnish komplett pelda
# http://www.adobe.com/devnet/adobe-media-server/articles/varnish-sample-for-failover.html

	# Origin server definition
	upstream origins {

		# Origin server list (round robin servicing)
		server stream.videosquare.eu;
		# server2 ...;

		# The keepalive parameter sets the maximum number of idle keepalive connections to upstream
		# servers that are preserved in the cache of each worker process. When this number is exceeded,
		# the least recently used connections are closed.
		keepalive 32;

	}

	# Include per site configuration files
	include /etc/nginx/conf.d/*.conf;
	include /etc/nginx/sites-enabled/*;

} # http
